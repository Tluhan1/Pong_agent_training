{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "from collections import deque \n",
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "import cv2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Player and Ball classes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "     \n",
    "    def __init__(self, xpos, ypos):\n",
    "        self.xpos = xpos\n",
    "        self.ypos = ypos\n",
    "        self.width = 10\n",
    "        self.height = 70\n",
    "        self.speed = 0 \n",
    "        self.ydir = 1\n",
    "        self.speed = 5\n",
    "    \n",
    "    def draw(self):\n",
    "        P = pygame.Rect(self.xpos, self.ypos, self.width, self.height) \n",
    "        pygame.draw.rect(screen,White,P)\n",
    "\n",
    "    def update(self,Ball_ydir):\n",
    "        self.speed += 2     \n",
    "        self.ypos += Ball_ydir*self.speed\n",
    "        if (self.ypos < 0):\n",
    "            self.ypos = 0\n",
    "        if (self.ypos > Win_h-self.height):\n",
    "            self.ypos = Win_h-self.height\n",
    "            \n",
    "    def auto_update(self,Ball_ypos, Ball_height, Ball_xdir):\n",
    "        if (self.ypos - self.height/2 < Ball_ypos - Ball_height/2 and Ball_xdir == 1):\n",
    "            self.ypos = self.ypos + self.speed\n",
    "        if (self.ypos + self.height/2 > Ball_ypos + Ball_height/2 and Ball_xdir == 1):\n",
    "            self.ypos = self.ypos - self.speed\n",
    "        if (self.ypos < 0):\n",
    "            self.ypos = int(Win_h/2)\n",
    "        if (self.ypos > Win_h - self.height/2):\n",
    "            self.ypos = int(Win_h/2)\n",
    "            \n",
    "    def learn_update(self,action):\n",
    "        #if move up\n",
    "        if (action[1] == 1):\n",
    "            self.ypos = self.ypos - self.speed\n",
    "        #if move down\n",
    "        if (action[2] == 1):\n",
    "            self.ypos = self.ypos + self.speed\n",
    "        if (self.ypos < 0):\n",
    "            self.ypos = int(Win_h/2)\n",
    "        if (self.ypos > Win_h - self.height/2):\n",
    "            self.ypos = int(Win_h/2) \n",
    "\n",
    "class Ball:\n",
    "     \n",
    "    def __init__(self, xpos, ypos):\n",
    "         \n",
    "        self.xpos = xpos\n",
    "        self.ypos = ypos\n",
    "        self.width = 10              \n",
    "        self.height = 10\n",
    "        self.xdir = 1\n",
    "        self.ydir = 1\n",
    "        self.xspeed = 2        \n",
    "        self.yspeed = 2 \n",
    "        \n",
    "        self.score = 0\n",
    "        self.score_value = 0\n",
    "        \n",
    "        self.right_limit = xpos + self.width/2\n",
    "        self.left_limit = xpos - self.width/2\n",
    "        self.up_limit = ypos - self.height/2\n",
    "        self.down_limit = ypos + self.height/2\n",
    "    \n",
    "    def draw(self):\n",
    "        B = pygame.Rect(self.xpos, self.ypos, self.width, self.height) # instead of ball\n",
    "        pygame.draw.rect(screen,White,B)\n",
    "        \n",
    "    \n",
    "    def update(self,buffer,player_w,player_ypos): \n",
    "        \n",
    "        self.xpos += self.xdir * self.xspeed\n",
    "        self.ypos += self.ydir * self.yspeed\n",
    "        \n",
    "        # Collision check: with the left and right limit\n",
    "        # Right side (player side):\n",
    "        if (int(self.xpos) >= Win_w-buffer-player_w):\n",
    "            if (int(self.ypos) not in range(player_ypos-35,player_ypos+35)): # Player misses the ball\n",
    "                self.xpos = Win_w-buffer-player_w\n",
    "                self.xdir = -1       \n",
    "                self.score = -1\n",
    "            elif (int(self.ypos) in range(player_ypos-35,player_ypos+35)):   # Player hits the ball\n",
    "                self.xpos = Win_w-player_w-buffer\n",
    "                self.xdir = -1 \n",
    "                self.score = 1\n",
    "                self.score_value += 1\n",
    "        # left side:    \n",
    "        elif (int(self.xpos) <= player_w):\n",
    "            self.xpos = player_w\n",
    "            self.xdir = 1\n",
    "            return \n",
    "                                                              \n",
    "        # Collision check with top and bottom:\n",
    "        if (self.ypos <= 0):               # if the ball hits the top:\n",
    "            self.ypos = 0\n",
    "            self.ydir = 1\n",
    "        elif(self.ypos >= Win_h-self.height):   # if the ball hits the bottom:\n",
    "            self.pos = Win_h-self.height-40\n",
    "            self.ydir = -1\n",
    "        return \n",
    "\n",
    "    def display_score(self):\n",
    "        text_font = pygame.font.Font(\"freesansbold.ttf\",14)\n",
    "        player1_text = text_font.render(f\"Score: {self.score_value}\",False,White)\n",
    "        screen.blit(player1_text,(410,480))\n",
    "        pygame.display.flip()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def getPresentFrame(Player,Ball):\n",
    "    pygame.event.pump()\n",
    "    screen.fill(Black)\n",
    "    Player.draw()\n",
    "    Ball.draw()\n",
    "    image_data = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "    screen.blit(pygame.transform.rotate(screen, -90), (0, 0))\n",
    "    pygame.display.flip()\n",
    "    Ball.display_score()\n",
    "    return image_data\n",
    "\n",
    "\n",
    "def getNextFrame(Player,Ball,action):\n",
    "    pygame.event.pump()\n",
    "    score = 0\n",
    "    screen.fill(Black)\n",
    "           \n",
    "#     Player.update(Ball.xdir) \n",
    "#     Player.auto_update(Ball.ypos, Ball.height, Ball.xdir)\n",
    "    Player.learn_update(action)\n",
    "                   \n",
    "    Player.draw()\n",
    "    Ball.update(buffer,int(Player.width),int(Player.ypos))\n",
    "    Ball.draw()\n",
    "    image_data = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "    screen.blit(pygame.transform.rotate(screen, -90), (0, 0))\n",
    "    pygame.display.flip()\n",
    "    Ball.display_score()\n",
    "    return [score,image_data]\n",
    "\n",
    "def createGraph():\n",
    "\n",
    "    #first convolutional layer. bias vector\n",
    "    #creates an empty tensor with all elements set to zero with a shape\n",
    "    W_conv1 = tf.Variable(tf.zeros([8, 8, 4, 32]))\n",
    "    b_conv1 = tf.Variable(tf.zeros([32]))\n",
    "\n",
    "    W_conv2 = tf.Variable(tf.zeros([4, 4, 32, 64]))\n",
    "    b_conv2 = tf.Variable(tf.zeros([64]))\n",
    "\n",
    "    W_conv3 = tf.Variable(tf.zeros([3, 3, 64, 64]))\n",
    "    b_conv3 = tf.Variable(tf.zeros([64]))\n",
    "\n",
    "    W_fc4 = tf.Variable(tf.zeros([3136, 784]))\n",
    "    b_fc4 = tf.Variable(tf.zeros([784]))\n",
    "\n",
    "    W_fc5 = tf.Variable(tf.zeros([784, ACTIONS]))\n",
    "    b_fc5 = tf.Variable(tf.zeros([ACTIONS]))\n",
    "\n",
    "    #input for pixel data\n",
    "    s = tf.placeholder(\"float\", [None, 84, 84, 4])\n",
    "\n",
    "    #Computes rectified linear unit activation fucntion on  a 2-D convolution given 4-D input and filter tensors. and \n",
    "    conv1 = tf.nn.relu(tf.nn.conv2d(s, W_conv1, strides = [1, 4, 4, 1], padding = \"VALID\") + b_conv1)\n",
    "    conv2 = tf.nn.relu(tf.nn.conv2d(conv1, W_conv2, strides = [1, 2, 2, 1], padding = \"VALID\") + b_conv2)\n",
    "    conv3 = tf.nn.relu(tf.nn.conv2d(conv2, W_conv3, strides = [1, 1, 1, 1], padding = \"VALID\") + b_conv3)\n",
    "    conv3_flat = tf.reshape(conv3, [-1, 3136])\n",
    "    fc4 = tf.nn.relu(tf.matmul(conv3_flat, W_fc4) + b_fc4)\n",
    "    fc5 = tf.matmul(fc4, W_fc5) + b_fc5\n",
    "\n",
    "    return s, fc5\n",
    "\n",
    "\n",
    "#deep q network. feed in pixel data to graph session \n",
    "def trainGraph(inp, out, sess):\n",
    "    \n",
    "    # intantiate player and ball objects:\n",
    "    player = Player(Win_w-buffer-10, Win_h/2-35)\n",
    "    ball = Ball(Win_w/2-5,Win_h/2-5)\n",
    "    \n",
    "    #to calculate the argmax, we multiply the predicted output with a vector with one value 1 and rest as 0\n",
    "    argmax = tf.placeholder(\"float\", [None, ACTIONS]) \n",
    "    gt = tf.placeholder(\"float\", [None]) #ground truth\n",
    "\n",
    "    #action\n",
    "    action = tf.reduce_sum(tf.multiply(out, argmax), reduction_indices = 1)\n",
    "    #cost function we will reduce through backpropagation\n",
    "    cost = tf.reduce_mean(tf.square(action - gt))\n",
    "    #optimization fucntion to reduce our minimize our cost function \n",
    "    train_step = tf.train.AdamOptimizer(1e-6).minimize(cost)\n",
    "\n",
    "    #create a queue for experience replay to store policies\n",
    "    D = deque()\n",
    "    \n",
    "    #intial frame\n",
    "    frame = getPresentFrame(player,ball)\n",
    "       \n",
    "    #convert rgb to gray scale for processing\n",
    "    frame = cv2.cvtColor(cv2.resize(frame, (84, 84)), cv2.COLOR_BGR2GRAY)\n",
    "    #binary colors, black or white\n",
    "    ret, frame = cv2.threshold(frame, 1, 255, cv2.THRESH_BINARY)\n",
    "    #stack frames, that is our input tensor\n",
    "    inp_t = np.stack((frame, frame, frame, frame), axis = 2)\n",
    "\n",
    "    #saver\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    t = 0\n",
    "    epsilon = INITIAL_EPSILON\n",
    "    #training time\n",
    "    while True:\n",
    "        \n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT: \n",
    "                pygame.quit()\n",
    "                break #sys.exit()\n",
    "            elif event.type == pygame.KEYDOWN:         \n",
    "                if event.key == pygame.K_ESCAPE:\n",
    "                    pygame.quit()\n",
    "                    break # sys.exit()\n",
    "        \n",
    "        #output tensor\n",
    "        out_t = out.eval(feed_dict = {inp : [inp_t]})[0]\n",
    "        #argmax function\n",
    "        argmax_t = np.zeros([ACTIONS])\n",
    "\n",
    "        if(random.random() <= epsilon):\n",
    "            maxIndex = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            maxIndex = np.argmax(out_t)\n",
    "        argmax_t[maxIndex] = 1\n",
    "        \n",
    "        if epsilon > FINAL_EPSILON:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "        #reward tensor if score is positive\n",
    "        reward_t, frame = getNextFrame(player,ball,argmax_t)\n",
    "        \n",
    "        #get frame pixel data\n",
    "        frame = cv2.cvtColor(cv2.resize(frame, (84, 84)), cv2.COLOR_BGR2GRAY)\n",
    "        ret, frame = cv2.threshold(frame, 1, 255, cv2.THRESH_BINARY)\n",
    "        frame = np.reshape(frame, (84, 84, 1))\n",
    "        #new input tensor\n",
    "        inp_t1 = np.append(frame, inp_t[:, :, 0:3], axis = 2)\n",
    "        \n",
    "        #add our input tensor, argmax tensor, reward and updated input tensor tos tack of experiences\n",
    "        D.append((inp_t, argmax_t, reward_t, inp_t1))\n",
    "\n",
    "        #if we run out of replay memory, make room\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "        \n",
    "        #training iteration\n",
    "        if t > OBSERVE:\n",
    "\n",
    "            #get values from our replay memory\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "        \n",
    "            inp_batch = [d[0] for d in minibatch]\n",
    "            argmax_batch = [d[1] for d in minibatch]\n",
    "            reward_batch = [d[2] for d in minibatch]\n",
    "            inp_t1_batch = [d[3] for d in minibatch]\n",
    "        \n",
    "            gt_batch = []\n",
    "            out_batch = out.eval(feed_dict = {inp : inp_t1_batch})\n",
    "            \n",
    "            #add values to our batch\n",
    "            for i in range(0, len(minibatch)):\n",
    "                gt_batch.append(reward_batch[i] + GAMMA * np.max(out_batch[i]))\n",
    "\n",
    "            #train on that \n",
    "            train_step.run(feed_dict = {\n",
    "                           gt : gt_batch,\n",
    "                           argmax : argmax_batch,\n",
    "                           inp : inp_batch\n",
    "                           })\n",
    "        \n",
    "        #update our input tensor the the next frame\n",
    "        inp_t = inp_t1\n",
    "        t = t+1\n",
    "        \n",
    "        if (t % 10000 == 0):\n",
    "            print(\"TIMESTEP\", t, \"/ EPSILON\", epsilon, \"/ ACTION\", maxIndex, \"/ REWARD\", reward_t, \"/ Q_MAX %e\" % np.max(out_t))\n",
    "#         #print our where wer are after saving where we are\n",
    "#         if t % 10000 == 0:\n",
    "#             saver.save(sess, './' + 'pong' + '-dqn', global_step = t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main: Train agent:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\za00235\\AppData\\Local\\Continuum\\anaconda3\\envs\\Test_Env\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:235: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-abc10154f031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#train our graph on input and output with session variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtrainGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-77ffd3245c38>\u001b[0m in \u001b[0;36mtrainGraph\u001b[1;34m(inp, out, sess)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m#reward tensor if score is positive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mreward_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetNextFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mball\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margmax_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m#get frame pixel data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-77ffd3245c38>\u001b[0m in \u001b[0;36mgetNextFrame\u001b[1;34m(Player, Ball, action)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetNextFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mscreen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBlack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "#hyper params\n",
    "ACTIONS = 3 #up,down, stay\n",
    "#define our learning rate\n",
    "GAMMA = 0.99\n",
    "#for updating our gradient or training over time\n",
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.05\n",
    "#how many frames to anneal epsilon\n",
    "EXPLORE = 500000 \n",
    "OBSERVE = 50000\n",
    "#store our experiences, the size of it\n",
    "REPLAY_MEMORY = 500000\n",
    "#batch size to train on\n",
    "BATCH = 100\n",
    "\n",
    "# Variables for the game:\n",
    "speed = 60               \n",
    "Win_w = 500             \n",
    "Win_h = 500  \n",
    "White = (255,255,255)\n",
    "Black = (0,0,0)\n",
    "buffer = 40\n",
    "Player_speed = 0\n",
    "\n",
    "\n",
    "# initialize game:\n",
    "pygame.init()\n",
    "# clock = pygame.time.Clock() \n",
    "screen = pygame.display.set_mode((Win_w, Win_h)) # instead of SCREEN\n",
    "pygame.display.set_caption(\"Thierry's Pong\")\n",
    "\n",
    "#create session\n",
    "sess = tf.InteractiveSession()\n",
    "#input layer and output layer by creating graph\n",
    "inp, out = createGraph()\n",
    "#train our graph on input and output with session variables\n",
    "trainGraph(inp, out, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test_Env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
